# VLG Pixel Play: Video Anomaly Detection ğŸ¥ğŸš¨

![Status](https://img.shields.io/badge/Status-Completed-success)
![Score](https://img.shields.io/badge/AP_Score-72%25-brightgreen)
![Python](https://img.shields.io/badge/Python-3.10-blue)
![Framework](https://img.shields.io/badge/PyTorch-2.0-orange)

**Name:** Harshit Agrawal

**Enrollment No.:** 25125017

**Branch:** Btech DSAI

**Year:** 1st

## ğŸ“Œ Project Overview
This project was developed for the **VLG Pixel Play** competition. The goal is to develop a robust computer vision model capable of detecting **anomalous events** in surveillance footage.

In a real-world environment, the challenge is to distinguish between standard background activities (crowds, traffic) and significant deviations (accidents, violence, unusual objects). The model is trained on **unlabeled normal activities** and tested on a dataset containing both normal and anomalous events.

### ğŸ† Achievement
**Final Score: 72% Average Precision (AP)** achieved using a custom **Quad-Model Ensemble** technique.

---

## ğŸ—ï¸ Model Architecture: The Quad-Model Ensemble
Instead of relying on a single architecture, this solution combines four distinct approaches to maximize robust detection:

1.  **STAE (Spatio-Temporal Autoencoder):** Captures temporal motion and spatial features simultaneously to detect deviations in movement patterns.
2.  **Roadmap (Lite):** A modified, efficient version of the Roadmap architecture, optimized for faster inference without losing accuracy.
3.  **U-Net Reconstructor:** A high-fidelity reconstruction network. High reconstruction error = Anomaly.
4.  **Joint Representation:** A specialized model focusing on learning the joint distribution of appearance (spatial) and motion (temporal) features.

The final output is generated by an **Ensemble Voting Script** that weighs the probability scores from all four models.

![Different Models Anomaly score and final weighted average of them.](Visuals/Essemble_vid3.png)  
---

## ğŸ“‚ Repository Structure
The repository is organized to separate production-ready code from research experiments:

```text
â”œâ”€â”€ Final_codes/             # âœ… MAIN SUBMISSION CODE
â”‚   â”œâ”€â”€ Enssemble_code/      # Scripts to combine model outputs
â”‚   â”œâ”€â”€ Final_models/        # Weight Files for the 4 best models
â”‚   â””â”€â”€ training_notebooks   # Notebooks used for training and testing the final models
â”‚
â”œâ”€â”€ experimental/            # ğŸ§ª Research & Archives
â”‚   â”œâ”€â”€ models/              # Alternative architectures tested
â”‚   â”œâ”€â”€ notebooks/           # Experimental training runs
â”‚   â””â”€â”€ submissions/         # Intermediate CSV outputs
â”‚
â”œâ”€â”€ visuals/                 # ğŸ“Š Graphs, Loss Curves, and Architecture Diagrams
â”‚
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md                # Project Documentation
```
ğŸš€ Installation & Usage (Kaggle Workflow)

This repository is designed to be fully reproducible within a Kaggle Notebook environment.

Step 1: Environment Setup

Clone this repository into the working directory:
```
!git clone https://github.com/harshit-iitr/VLG_Pixel_play
```

Step 2: Install Dependencies

Navigate to the cloned folder and install the required libraries:
```
%cd VLG-Pixel-Play-VAD
!pip install -r requirements.txt
```

Step 3: âš ï¸ CRITICAL: Path Configuration

1. Copy or Import the codes and notebook from /VLG_Pixel_play/Final_Codes you want to run.
2. Before running, check all the paths to models and files. 
3. The ready to use trained models weights are stored in /VLG_Pixel_play/Final_Codes/Final_models


Step 4: Reproducing the Result

To generate the final 72% AP submission:

Generate Individual Scores: Run the notebooks in Final_codes/Final_models/ to generate the prediction CSV for each of the 4 models.

Run the Enssemble:
```
%cd Final_Codes/Essemble Script
!python Enssemble Script.py
```

Output: The script will produce submission_quad_essemble.csv in the current directory.

ğŸ“Š Visuals

Detailed performance graphs and some denoised/noisy videos can be found in the visuals/ directory.


