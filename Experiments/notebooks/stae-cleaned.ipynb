{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbea7098",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-02T15:04:48.857166Z",
     "iopub.status.busy": "2026-01-02T15:04:48.856919Z",
     "iopub.status.idle": "2026-01-02T15:07:42.011825Z",
     "shell.execute_reply": "2026-01-02T15:07:42.010827Z"
    },
    "papermill": {
     "duration": 173.160414,
     "end_time": "2026-01-02T15:07:42.013522",
     "exception": false,
     "start_time": "2026-01-02T15:04:48.853108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11706 frames to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11706/11706 [02:28<00:00, 78.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Cleaning Complete!\n",
      "Total Images: 11706\n",
      "Images Flipped/Fixed: 1195\n",
      "Cleaned dataset saved to: /kaggle/working/cleaned_testing_videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Path to the CORRUPTED testing videos\n",
    "TEST_DATA_DIR = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos'\n",
    "\n",
    "# Path where we will save the CLEANED videos\n",
    "CLEAN_DATA_DIR = '/kaggle/working/cleaned_testing_videos'\n",
    "\n",
    "MODEL_PATH = '/kaggle/input/flipercorrectorvlg/pytorch/default/1/rotnet_model(1).pth'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# =================================================\n",
    "\n",
    "def clean_dataset():\n",
    "    print(f\"Processing on: {DEVICE}\")\n",
    "    \n",
    "    # 1. Load the Trained RotNet\n",
    "    model = models.resnet18(pretrained=False) # No need to download weights again\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2) # Matches our binary training\n",
    "    \n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    # Standard transform for the model input\n",
    "    # Note: We do NOT augment here, just resize/norm\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 2. Find all images\n",
    "    # We walk through the directory to keep structure\n",
    "    image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, '**', '*.jpg'), recursive=True))\n",
    "    print(f\"Found {len(image_paths)} frames to process.\")\n",
    "    \n",
    "    # 3. Processing Loop\n",
    "    flip_count = 0\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Cleaning\"):\n",
    "        # A. Setup paths\n",
    "        # Get relative path (e.g., \"01/frame_0001.jpg\") to maintain structure\n",
    "        rel_path = os.path.relpath(img_path, TEST_DATA_DIR)\n",
    "        save_path = os.path.join(CLEAN_DATA_DIR, rel_path)\n",
    "        \n",
    "        # Create folder if not exists\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        \n",
    "        # B. Predict Rotation\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = preprocess(image).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            label = predicted.item()\n",
    "            \n",
    "        # C. Fix and Save\n",
    "        # Label 0 = Upright (Keep as is)\n",
    "        # Label 1 = Flipped (Needs 180 rotation to fix)\n",
    "        \n",
    "        if label == 1:\n",
    "            # It was detected as Upside Down, so we rotate it -180 (or 180) to fix\n",
    "            fixed_image = image.transpose(Image.FLIP_TOP_BOTTOM) \n",
    "            flip_count += 1\n",
    "        else:\n",
    "            fixed_image = image\n",
    "            \n",
    "        # Save the fixed image\n",
    "        fixed_image.save(save_path)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Cleaning Complete!\")\n",
    "    print(f\"Total Images: {len(image_paths)}\")\n",
    "    print(f\"Images Flipped/Fixed: {flip_count}\")\n",
    "    print(f\"Cleaned dataset saved to: {CLEAN_DATA_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d101638c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:07:42.112085Z",
     "iopub.status.busy": "2026-01-02T15:07:42.111721Z",
     "iopub.status.idle": "2026-01-02T15:17:17.657695Z",
     "shell.execute_reply": "2026-01-02T15:17:17.656824Z"
    },
    "papermill": {
     "duration": 575.596595,
     "end_time": "2026-01-02T15:17:17.659518",
     "exception": false,
     "start_time": "2026-01-02T15:07:42.062923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Cloning FastDVDnet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastdvdnet'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (25.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.5)\n",
      "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 87.2/87.2 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2026-01-02 15:07:48--  https://github.com/m-tassano/fastdvdnet/raw/master/model.pth\n",
      "Resolving github.com (github.com)... 140.82.116.3\n",
      "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/m-tassano/fastdvdnet/master/model.pth [following]\n",
      "--2026-01-02 15:07:49--  https://raw.githubusercontent.com/m-tassano/fastdvdnet/master/model.pth\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9971551 (9.5M) [application/octet-stream]\n",
      "Saving to: ‚Äòfastdvdnet/model/model.pth‚Äô\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 8.15M 1s\n",
      "    50K .......... .......... .......... .......... ..........  1% 9.41M 1s\n",
      "   100K .......... .......... .......... .......... ..........  1% 31.2M 1s\n",
      "   150K .......... .......... .......... .......... ..........  2% 52.7M 1s\n",
      "   200K .......... .......... .......... .......... ..........  2% 56.8M 1s\n",
      "   250K .......... .......... .......... .......... ..........  3% 12.4M 1s\n",
      "   300K .......... .......... .......... .......... ..........  3%  106M 1s\n",
      "   350K .......... .......... .......... .......... ..........  4% 56.5M 0s\n",
      "   400K .......... .......... .......... .......... ..........  4%  106M 0s\n",
      "   450K .......... .......... .......... .......... ..........  5%  174M 0s\n",
      "   500K .......... .......... .......... .......... ..........  5% 21.0M 0s\n",
      "   550K .......... .......... .......... .......... ..........  6% 34.9M 0s\n",
      "   600K .......... .......... .......... .......... ..........  6%  112M 0s\n",
      "   650K .......... .......... .......... .......... ..........  7%  208M 0s\n",
      "   700K .......... .......... .......... .......... ..........  7%  243M 0s\n",
      "   750K .......... .......... .......... .......... ..........  8% 92.8M 0s\n",
      "   800K .......... .......... .......... .......... ..........  8%  170M 0s\n",
      "   850K .......... .......... .......... .......... ..........  9%  236M 0s\n",
      "   900K .......... .......... .......... .......... ..........  9%  330M 0s\n",
      "   950K .......... .......... .......... .......... .......... 10%  127M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 10% 24.3M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 11%  207M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 11% 49.9M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 12%  211M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 12%  176M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 13%  199M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 13%  338M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 14%  313M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 14%  298M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 15%  348M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 15%  360M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 16%  318M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 16%  203M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 17%  217M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 17%  304M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 18%  340M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 18%  259M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 19%  184M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 20%  222M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 20%  278M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 21% 43.5M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 21%  171M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 22%  258M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 22%  355M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 23%  300M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 23% 72.3M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 24%  214M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 24%  270M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 25%  279M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 25%  301M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 26%  249M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 26%  318M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 27%  253M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 27%  322M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 28%  319M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 28%  276M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 29%  217M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 29%  197M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 30%  218M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 30%  290M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 31%  323M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 31%  225M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 32%  182M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 32%  270M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 33%  354M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 33%  326M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 34%  226M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 34%  202M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 35%  316M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 35%  319M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 36%  282M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 36%  336M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 37%  153M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 37%  218M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 38%  201M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 39%  298M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 39%  193M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 40%  194M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 40%  267M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 41%  346M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 41%  298M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 42%  204M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 42%  150M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 43%  182M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 43%  284M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 44%  186M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 44%  195M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 45%  144M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 45%  301M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 46%  219M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 46%  284M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 47%  306M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 47%  273M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 48%  348M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 48%  364M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 49%  160M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 49%  211M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 50%  155M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 50%  286M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 51%  198M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 51%  241M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 52%  213M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 52%  340M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 53%  310M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 53%  259M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 54%  315M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 54%  301M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 55%  337M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 55%  357M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 56%  325M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 56%  181M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 57%  193M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 58%  242M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 58%  312M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 59%  319M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 59%  201M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 60%  190M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 60%  243M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 61%  317M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 61%  274M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 62%  214M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 62%  191M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 63%  229M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 63%  301M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 64%  308M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 64%  193M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 65%  188M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 65%  286M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 66%  325M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 66%  244M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 67%  242M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 67%  357M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 68%  351M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 68%  309M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 69%  264M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 69%  327M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 70%  172M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 70%  258M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 71%  265M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 71%  316M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 72%  338M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 72%  248M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 73%  204M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 73%  338M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 74%  363M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 74%  368M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 75%  305M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 75%  324M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 76%  349M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 77%  362M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 77%  306M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 78%  364M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 78%  368M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 79%  320M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 79%  172M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 80%  214M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 80%  220M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 81%  248M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 81%  233M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 82%  214M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 82%  265M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 83%  353M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 83%  323M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 84%  335M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 84%  281M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 85%  232M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 85%  288M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 86%  357M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 86%  351M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 87%  343M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 87%  244M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 88%  213M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 88%  223M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 89%  228M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 89%  164M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 90%  237M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 90%  238M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 91%  349M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 91%  361M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 92%  352M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 92%  239M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 93%  238M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 93%  325M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 94%  329M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 94%  354M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 95%  293M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 96%  296M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 96%  222M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 97%  250M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 97%  335M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 98%  306M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 98%  344M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 99%  215M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 99%  251M 0s\n",
      "  9700K .......... .......... .......... .......              100%  202M=0.06s\n",
      "\n",
      "2026-01-02 15:07:49 (148 MB/s) - ‚Äòfastdvdnet/model/model.pth‚Äô saved [9971551/9971551]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Found 21 videos to clean.\n",
      "\n",
      "üé¨ Processing Video: 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76/76 [00:56<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:34<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:44<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:28<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:34<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:23<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:34<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:25<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:24<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:35<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:35<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:20<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:14<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:13<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ‚úÖ‚úÖ ALL VIDEOS CLEANED! Saved to: /kaggle/working/denoised_dataset_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# 1. WHERE ARE YOUR NOISY FRAMES?\n",
    "# Adjust this to the root folder containing '01', '02', etc.\n",
    "INPUT_ROOT = \"/kaggle/working/cleaned_testing_videos\" \n",
    "\n",
    "# 2. WHERE TO SAVE CLEAN FRAMES?\n",
    "OUTPUT_ROOT = \"/kaggle/working/denoised_dataset_test\"\n",
    "\n",
    "# 3. SETTINGS (The Winning Formula)\n",
    "NOISE_SIGMA = 40 / 255.0  \n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "# =================================================\n",
    "\n",
    "# --- UTILS ---\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def install_and_setup():\n",
    "    if not os.path.exists(\"fastdvdnet\"):\n",
    "        print(\"üõ†Ô∏è Cloning FastDVDnet...\")\n",
    "        os.system(\"git clone https://github.com/m-tassano/fastdvdnet.git\")\n",
    "        os.system(\"pip install tensorboardX\")\n",
    "    \n",
    "    if not os.path.exists(\"fastdvdnet/model/model.pth\"):\n",
    "        os.makedirs(\"fastdvdnet/model\", exist_ok=True)\n",
    "        os.system(\"wget -O fastdvdnet/model/model.pth https://github.com/m-tassano/fastdvdnet/raw/master/model.pth\")\n",
    "\n",
    "# --- DATASET ---\n",
    "class FrameSequenceDataset(Dataset):\n",
    "    def __init__(self, frame_paths):\n",
    "        self.frame_paths = frame_paths\n",
    "        self.total = len(frame_paths)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Sliding Window of 5 frames\n",
    "        indices = [max(0, min(self.total - 1, idx + offset)) for offset in range(-2, 3)]\n",
    "        \n",
    "        frames = []\n",
    "        for i in indices:\n",
    "            path = self.frame_paths[i]\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                img = np.zeros((360, 640, 3), dtype=np.uint8) # Fallback size\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            frames.append(img)\n",
    "            \n",
    "        stack = np.concatenate(frames, axis=2) # (H, W, 15)\n",
    "        tensor = torch.from_numpy(stack).permute(2, 0, 1) # (15, H, W)\n",
    "        return tensor\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "def run_mass_cleaning():\n",
    "    install_and_setup()\n",
    "    \n",
    "    # Import Model\n",
    "    sys.path.append(\"fastdvdnet\")\n",
    "    try:\n",
    "        from models import FastDVDnet\n",
    "    except ImportError:\n",
    "        from fastdvdnet.models import FastDVDnet\n",
    "\n",
    "    # Find all video folders (01, 02, ... 21)\n",
    "    video_folders = sorted(glob.glob(os.path.join(INPUT_ROOT, \"*\")))\n",
    "    # Filter to ensure they are directories\n",
    "    video_folders = [f for f in video_folders if os.path.isdir(f)]\n",
    "    \n",
    "    print(f\"üåç Found {len(video_folders)} videos to clean.\")\n",
    "\n",
    "    # Setup Model Once\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FastDVDnet(num_input_frames=5)\n",
    "    \n",
    "    state_dict = torch.load(\"fastdvdnet/model/model.pth\", map_location=device)\n",
    "    new_state = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"üî• Dual GPU Active\")\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # --- LOOP OVER VIDEOS ---\n",
    "    for vid_path in video_folders:\n",
    "        vid_id = os.path.basename(vid_path)\n",
    "        print(f\"\\nüé¨ Processing Video: {vid_id}\")\n",
    "        \n",
    "        # 1. Get Frames\n",
    "        files = glob.glob(os.path.join(vid_path, \"*\"))\n",
    "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        files.sort(key=lambda x: natural_sort_key(os.path.basename(x)))\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"‚ö†Ô∏è Skipping {vid_id} (No images found)\")\n",
    "            continue\n",
    "            \n",
    "        # 2. Setup Output Folder\n",
    "        save_dir = os.path.join(OUTPUT_ROOT, vid_id)\n",
    "        if os.path.exists(save_dir): shutil.rmtree(save_dir)\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "        # 3. Process\n",
    "        dataset = FrameSequenceDataset(files)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(tqdm(loader, desc=f\"Cleaning {vid_id}\")):\n",
    "                data = data.to(device)\n",
    "                B, C, H, W = data.shape\n",
    "                \n",
    "                noise_sigma = torch.full((B, 1, H, W), NOISE_SIGMA).to(device)\n",
    "                \n",
    "                clean_batch = model(data, noise_sigma)\n",
    "                clean_batch = clean_batch.permute(0, 2, 3, 1).cpu().numpy()\n",
    "                \n",
    "                for i in range(B):\n",
    "                    img = np.clip(clean_batch[i] * 255, 0, 255).astype(np.uint8)\n",
    "                    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    # Standardized Name: frame_0000.jpg\n",
    "                    global_idx = batch_idx * BATCH_SIZE + i\n",
    "                    save_name = f\"frame_{global_idx:04d}.jpg\"\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(save_dir, save_name), img_bgr)\n",
    "                    \n",
    "    print(f\"\\n‚úÖ‚úÖ‚úÖ ALL VIDEOS CLEANED! Saved to: {OUTPUT_ROOT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_mass_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5999246d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:17:17.816215Z",
     "iopub.status.busy": "2026-01-02T15:17:17.815883Z",
     "iopub.status.idle": "2026-01-02T15:24:43.636099Z",
     "shell.execute_reply": "2026-01-02T15:24:43.635073Z"
    },
    "papermill": {
     "duration": 445.899761,
     "end_time": "2026-01-02T15:24:43.637539",
     "exception": false,
     "start_time": "2026-01-02T15:17:17.737778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Found 16 videos to clean.\n",
      "\n",
      "üé¨ Processing Video: 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:30<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:37<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:24<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:33<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:33<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:24<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53/53 [00:39<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:33<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:34<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:36<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:17<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:24<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:17<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Processing Video: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:12<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ‚úÖ‚úÖ ALL VIDEOS CLEANED! Saved to: /kaggle/working/denoised_dataset_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# 1. WHERE ARE YOUR NOISY FRAMES?\n",
    "# Adjust this to the root folder containing '01', '02', etc.\n",
    "INPUT_ROOT = \"/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/training_videos\" \n",
    "\n",
    "# 2. WHERE TO SAVE CLEAN FRAMES?\n",
    "OUTPUT_ROOT = \"/kaggle/working/denoised_dataset_train\"\n",
    "\n",
    "# 3. SETTINGS (The Winning Formula)\n",
    "NOISE_SIGMA = 40 / 255.0  \n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "# =================================================\n",
    "\n",
    "# --- UTILS ---\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def install_and_setup():\n",
    "    if not os.path.exists(\"fastdvdnet\"):\n",
    "        print(\"üõ†Ô∏è Cloning FastDVDnet...\")\n",
    "        os.system(\"git clone https://github.com/m-tassano/fastdvdnet.git\")\n",
    "        os.system(\"pip install tensorboardX\")\n",
    "    \n",
    "    if not os.path.exists(\"fastdvdnet/model/model.pth\"):\n",
    "        os.makedirs(\"fastdvdnet/model\", exist_ok=True)\n",
    "        os.system(\"wget -O fastdvdnet/model/model.pth https://github.com/m-tassano/fastdvdnet/raw/master/model.pth\")\n",
    "\n",
    "# --- DATASET ---\n",
    "class FrameSequenceDataset(Dataset):\n",
    "    def __init__(self, frame_paths):\n",
    "        self.frame_paths = frame_paths\n",
    "        self.total = len(frame_paths)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Sliding Window of 5 frames\n",
    "        indices = [max(0, min(self.total - 1, idx + offset)) for offset in range(-2, 3)]\n",
    "        \n",
    "        frames = []\n",
    "        for i in indices:\n",
    "            path = self.frame_paths[i]\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                img = np.zeros((360, 640, 3), dtype=np.uint8) # Fallback size\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            frames.append(img)\n",
    "            \n",
    "        stack = np.concatenate(frames, axis=2) # (H, W, 15)\n",
    "        tensor = torch.from_numpy(stack).permute(2, 0, 1) # (15, H, W)\n",
    "        return tensor\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "def run_mass_cleaning():\n",
    "    install_and_setup()\n",
    "    \n",
    "    # Import Model\n",
    "    sys.path.append(\"fastdvdnet\")\n",
    "    try:\n",
    "        from models import FastDVDnet\n",
    "    except ImportError:\n",
    "        from fastdvdnet.models import FastDVDnet\n",
    "\n",
    "    # Find all video folders (01, 02, ... 21)\n",
    "    video_folders = sorted(glob.glob(os.path.join(INPUT_ROOT, \"*\")))\n",
    "    # Filter to ensure they are directories\n",
    "    video_folders = [f for f in video_folders if os.path.isdir(f)]\n",
    "    \n",
    "    print(f\"üåç Found {len(video_folders)} videos to clean.\")\n",
    "\n",
    "    # Setup Model Once\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FastDVDnet(num_input_frames=5)\n",
    "    \n",
    "    state_dict = torch.load(\"fastdvdnet/model/model.pth\", map_location=device)\n",
    "    new_state = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"üî• Dual GPU Active\")\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # --- LOOP OVER VIDEOS ---\n",
    "    for vid_path in video_folders:\n",
    "        vid_id = os.path.basename(vid_path)\n",
    "        print(f\"\\nüé¨ Processing Video: {vid_id}\")\n",
    "        \n",
    "        # 1. Get Frames\n",
    "        files = glob.glob(os.path.join(vid_path, \"*\"))\n",
    "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        files.sort(key=lambda x: natural_sort_key(os.path.basename(x)))\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"‚ö†Ô∏è Skipping {vid_id} (No images found)\")\n",
    "            continue\n",
    "            \n",
    "        # 2. Setup Output Folder\n",
    "        save_dir = os.path.join(OUTPUT_ROOT, vid_id)\n",
    "        if os.path.exists(save_dir): shutil.rmtree(save_dir)\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "        # 3. Process\n",
    "        dataset = FrameSequenceDataset(files)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(tqdm(loader, desc=f\"Cleaning {vid_id}\")):\n",
    "                data = data.to(device)\n",
    "                B, C, H, W = data.shape\n",
    "                \n",
    "                noise_sigma = torch.full((B, 1, H, W), NOISE_SIGMA).to(device)\n",
    "                \n",
    "                clean_batch = model(data, noise_sigma)\n",
    "                clean_batch = clean_batch.permute(0, 2, 3, 1).cpu().numpy()\n",
    "                \n",
    "                for i in range(B):\n",
    "                    img = np.clip(clean_batch[i] * 255, 0, 255).astype(np.uint8)\n",
    "                    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    # Standardized Name: frame_0000.jpg\n",
    "                    global_idx = batch_idx * BATCH_SIZE + i\n",
    "                    save_name = f\"frame_{global_idx:04d}.jpg\"\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(save_dir, save_name), img_bgr)\n",
    "                    \n",
    "    print(f\"\\n‚úÖ‚úÖ‚úÖ ALL VIDEOS CLEANED! Saved to: {OUTPUT_ROOT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_mass_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724e5f2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:24:43.852168Z",
     "iopub.status.busy": "2026-01-02T15:24:43.851454Z",
     "iopub.status.idle": "2026-01-02T15:24:43.988022Z",
     "shell.execute_reply": "2026-01-02T15:24:43.987012Z"
    },
    "papermill": {
     "duration": 0.247513,
     "end_time": "2026-01-02T15:24:43.989791",
     "exception": false,
     "start_time": "2026-01-02T15:24:43.742278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92f66ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:24:44.203585Z",
     "iopub.status.busy": "2026-01-02T15:24:44.202845Z",
     "iopub.status.idle": "2026-01-02T15:35:49.673170Z",
     "shell.execute_reply": "2026-01-02T15:35:49.672449Z"
    },
    "papermill": {
     "duration": 665.686207,
     "end_time": "2026-01-02T15:35:49.781276",
     "exception": false,
     "start_time": "2026-01-02T15:24:44.095069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Optical Flow Maps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [11:05<00:00, 41.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CONFIG\n",
    "# Use your Neural Cleaned videos for best flow calculation\n",
    "SOURCE_DIR = '/kaggle/working/denoised_dataset_train'\n",
    "DEST_DIR = '/kaggle/working/training_optical_flow'\n",
    "\n",
    "def extract_optical_flow():\n",
    "    if not os.path.exists(DEST_DIR): os.makedirs(DEST_DIR)\n",
    "    \n",
    "    print(\"Generating Optical Flow Maps...\")\n",
    "    \n",
    "    for vid in tqdm(sorted(os.listdir(SOURCE_DIR))):\n",
    "        vid_path = os.path.join(SOURCE_DIR, vid)\n",
    "        save_path = os.path.join(DEST_DIR, vid)\n",
    "        if not os.path.isdir(vid_path): continue\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        frames = sorted(glob.glob(os.path.join(vid_path, '*.jpg')))\n",
    "        prev_frame = cv2.imread(frames[0])\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Save first flow as black (no motion) to keep frame count same\n",
    "        h, w = prev_gray.shape\n",
    "        blank_flow = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        cv2.imwrite(os.path.join(save_path, os.path.basename(frames[0])), blank_flow)\n",
    "        \n",
    "        for i in range(1, len(frames)):\n",
    "            curr_frame = cv2.imread(frames[i])\n",
    "            curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate Dense Optical Flow (Farneback)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, \n",
    "                                                0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            \n",
    "            # Visualize Flow as RGB Image\n",
    "            # Magnitude and Angle\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            \n",
    "            # HSV encoding\n",
    "            hsv = np.zeros_like(prev_frame)\n",
    "            hsv[..., 1] = 255\n",
    "            # Hue = Angle, Value = Magnitude (Speed)\n",
    "            hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "            hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            \n",
    "            # Convert to RGB for saving\n",
    "            rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_path, os.path.basename(frames[i])), rgb_flow)\n",
    "            \n",
    "            prev_gray = curr_gray\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_optical_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b303f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T15:35:49.994688Z",
     "iopub.status.busy": "2026-01-02T15:35:49.994153Z",
     "iopub.status.idle": "2026-01-02T16:21:41.083456Z",
     "shell.execute_reply": "2026-01-02T16:21:41.082484Z"
    },
    "papermill": {
     "duration": 2751.197575,
     "end_time": "2026-01-02T16:21:41.085162",
     "exception": false,
     "start_time": "2026-01-02T15:35:49.887587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training STAE on Precomputed Flow Maps (cuda)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:05<00:00,  1.35s/it, loss=0.0133]\n",
      "Ep 2/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:04<00:00,  1.35s/it, loss=0.0056]\n",
      "Ep 3/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00383]\n",
      "Ep 4/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00266]\n",
      "Ep 5/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.34s/it, loss=0.00301]\n",
      "Ep 6/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.33s/it, loss=0.00269]\n",
      "Ep 7/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.33s/it, loss=0.00257]\n",
      "Ep 8/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00201]\n",
      "Ep 9/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.33s/it, loss=0.00183]\n",
      "Ep 10/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.33s/it, loss=0.0023]\n",
      "Ep 11/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00232]\n",
      "Ep 12/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00208]\n",
      "Ep 13/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00183]\n",
      "Ep 14/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:03<00:00,  1.34s/it, loss=0.00178]\n",
      "Ep 15/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137/137 [03:02<00:00,  1.34s/it, loss=0.00232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DONE. Model saved to st_autoencoder_flow.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Path to your PRE-GENERATED Flow images\n",
    "FLOW_TRAIN_DIR = '/kaggle/working/training_optical_flow' \n",
    "MODEL_SAVE_PATH = 'st_autoencoder_flow.pth'\n",
    "\n",
    "BATCH_SIZE = 32  # Increased batch size since we are just loading images now\n",
    "EPOCHS = 15\n",
    "CLIP_LEN = 16\n",
    "IMG_SIZE = 128\n",
    "CHANNELS = 3     # RGB Flow maps\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# =================================================\n",
    "\n",
    "# --- 1. DATASET (Loads Pre-Computed Flow) ---\n",
    "class PrecomputedFlowDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, clip_length=16):\n",
    "        self.clips = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Find video folders inside the flow directory\n",
    "        # e.g. /training_optical_flow/01/, /training_optical_flow/02/\n",
    "        video_folders = sorted([f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))])\n",
    "        \n",
    "        for vid in video_folders:\n",
    "            vid_path = os.path.join(root_dir, vid)\n",
    "            frames = sorted(glob.glob(os.path.join(vid_path, '*.jpg'))) # or *.png\n",
    "            \n",
    "            # Ensure enough frames for input + target\n",
    "            if len(frames) < 2 * clip_length: continue\n",
    "            \n",
    "            # Stride 1 or 2 (Using 2 here to match previous logic)\n",
    "            for i in range(0, len(frames) - (2 * clip_length) + 1, 2): \n",
    "                input_paths = frames[i : i + clip_length]\n",
    "                target_paths = frames[i + clip_length : i + (2 * clip_length)]\n",
    "                self.clips.append((input_paths, target_paths))\n",
    "                \n",
    "    def __len__(self): return len(self.clips)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_paths, target_paths = self.clips[idx]\n",
    "        \n",
    "        def load_clip(paths):\n",
    "            # Load images. They are already RGB Flow maps.\n",
    "            # Convert to RGB to ensure 3 channels\n",
    "            clip = [Image.open(p).convert('RGB') for p in paths]\n",
    "            \n",
    "            if self.transform:\n",
    "                clip = [self.transform(img) for img in clip]\n",
    "                \n",
    "            # Stack: List of (C, H, W) -> (T, C, H, W)\n",
    "            # Permute to (C, T, H, W) for 3D Conv\n",
    "            return torch.stack(clip, dim=0).permute(1, 0, 2, 3)\n",
    "            \n",
    "        return load_clip(input_paths), load_clip(target_paths)\n",
    "\n",
    "# --- 2. MODEL (Same 3-Channel ST-AutoEncoder) ---\n",
    "class STAutoEncoder_Flow(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(STAutoEncoder_Flow, self).__init__()\n",
    "        # ENCODER (Input = 3 Channels)\n",
    "        self.conv1 = nn.Conv3d(3, 32, 3, padding=1); self.bn1 = nn.BatchNorm3d(32); self.pool1 = nn.MaxPool3d(2, 2)\n",
    "        self.conv2 = nn.Conv3d(32, 48, 3, padding=1); self.bn2 = nn.BatchNorm3d(48); self.pool2 = nn.MaxPool3d(2, 2)\n",
    "        self.conv3 = nn.Conv3d(48, 64, 3, padding=1); self.bn3 = nn.BatchNorm3d(64); self.pool3 = nn.MaxPool3d(2, 2)\n",
    "        self.conv4 = nn.Conv3d(64, 64, 3, padding=1); self.bn4 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        # DECODER - Reconstruction\n",
    "        self.rec_deconv1 = nn.ConvTranspose3d(64, 48, 3, 2, 1, 1); self.rec_bn1 = nn.BatchNorm3d(48)\n",
    "        self.rec_deconv2 = nn.ConvTranspose3d(48, 32, 3, 2, 1, 1); self.rec_bn2 = nn.BatchNorm3d(32)\n",
    "        self.rec_deconv3 = nn.ConvTranspose3d(32, 32, 3, 2, 1, 1); self.rec_bn3 = nn.BatchNorm3d(32)\n",
    "        self.rec_final = nn.Conv3d(32, 3, 3, padding=1) \n",
    "        \n",
    "        # DECODER - Prediction\n",
    "        self.pred_deconv1 = nn.ConvTranspose3d(64, 48, 3, 2, 1, 1); self.pred_bn1 = nn.BatchNorm3d(48)\n",
    "        self.pred_deconv2 = nn.ConvTranspose3d(48, 32, 3, 2, 1, 1); self.pred_bn2 = nn.BatchNorm3d(32)\n",
    "        self.pred_deconv3 = nn.ConvTranspose3d(32, 32, 3, 2, 1, 1); self.pred_bn3 = nn.BatchNorm3d(32)\n",
    "        self.pred_final = nn.Conv3d(32, 3, 3, padding=1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        l = self.relu(self.bn4(self.conv4(x))) \n",
    "        \n",
    "        # Reconstruction\n",
    "        r = self.relu(self.rec_bn1(self.rec_deconv1(l)))\n",
    "        r = self.relu(self.rec_bn2(self.rec_deconv2(r)))\n",
    "        r = self.relu(self.rec_bn3(self.rec_deconv3(r)))\n",
    "        r = self.sigmoid(self.rec_final(r))\n",
    "        \n",
    "        # Prediction\n",
    "        p = self.relu(self.pred_bn1(self.pred_deconv1(l)))\n",
    "        p = self.relu(self.pred_bn2(self.pred_deconv2(p)))\n",
    "        p = self.relu(self.pred_bn3(self.pred_deconv3(p)))\n",
    "        p = self.sigmoid(self.pred_final(p))\n",
    "        \n",
    "        return r, p\n",
    "\n",
    "# --- 3. TRAINING LOOP ---\n",
    "def train_precomputed_flow():\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "    print(f\"Training STAE on Precomputed Flow Maps ({DEVICE})...\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor() \n",
    "    ])\n",
    "    \n",
    "    # Using the new Dataset class\n",
    "    dataset = PrecomputedFlowDataset(FLOW_TRAIN_DIR, transform=transform, clip_length=CLIP_LEN)\n",
    "    \n",
    "    # We can now use more workers because we aren't using OpenCV on CPU\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    model = STAutoEncoder_Flow()\n",
    "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        loop = tqdm(loader, desc=f\"Ep {epoch+1}/{EPOCHS}\")\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for inp, tgt in loop:\n",
    "            inp, tgt = inp.to(DEVICE), tgt.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            rec, pred = model(inp)\n",
    "            \n",
    "            loss = criterion(rec, inp) + criterion(pred, tgt)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "    # Save\n",
    "    state = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "    torch.save(state, MODEL_SAVE_PATH)\n",
    "    print(f\"‚úÖ DONE. Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_precomputed_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13688340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T16:21:41.622991Z",
     "iopub.status.busy": "2026-01-02T16:21:41.622181Z",
     "iopub.status.idle": "2026-01-02T16:35:34.248979Z",
     "shell.execute_reply": "2026-01-02T16:35:34.248136Z"
    },
    "papermill": {
     "duration": 832.883607,
     "end_time": "2026-01-02T16:35:34.250635",
     "exception": false,
     "start_time": "2026-01-02T16:21:41.367028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Optical Flow Maps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [13:52<00:00, 39.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CONFIG\n",
    "# Use your Neural Cleaned videos for best flow calculation\n",
    "SOURCE_DIR = '/kaggle/working/denoised_dataset_test'\n",
    "DEST_DIR = '/kaggle/working/testing_optical_flow'\n",
    "\n",
    "def extract_optical_flow():\n",
    "    if not os.path.exists(DEST_DIR): os.makedirs(DEST_DIR)\n",
    "    \n",
    "    print(\"Generating Optical Flow Maps...\")\n",
    "    \n",
    "    for vid in tqdm(sorted(os.listdir(SOURCE_DIR))):\n",
    "        vid_path = os.path.join(SOURCE_DIR, vid)\n",
    "        save_path = os.path.join(DEST_DIR, vid)\n",
    "        if not os.path.isdir(vid_path): continue\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        frames = sorted(glob.glob(os.path.join(vid_path, '*.jpg')))\n",
    "        prev_frame = cv2.imread(frames[0])\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Save first flow as black (no motion) to keep frame count same\n",
    "        h, w = prev_gray.shape\n",
    "        blank_flow = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        cv2.imwrite(os.path.join(save_path, os.path.basename(frames[0])), blank_flow)\n",
    "        \n",
    "        for i in range(1, len(frames)):\n",
    "            curr_frame = cv2.imread(frames[i])\n",
    "            curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate Dense Optical Flow (Farneback)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, \n",
    "                                                0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            \n",
    "            # Visualize Flow as RGB Image\n",
    "            # Magnitude and Angle\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            \n",
    "            # HSV encoding\n",
    "            hsv = np.zeros_like(prev_frame)\n",
    "            hsv[..., 1] = 255\n",
    "            # Hue = Angle, Value = Magnitude (Speed)\n",
    "            hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "            hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            \n",
    "            # Convert to RGB for saving\n",
    "            rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_path, os.path.basename(frames[i])), rgb_flow)\n",
    "            \n",
    "            prev_gray = curr_gray\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_optical_flow()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15067517,
     "sourceId": 126766,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 543190,
     "modelInstanceId": 529173,
     "sourceId": 697643,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5451.725154,
   "end_time": "2026-01-02T16:35:38.156933",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T15:04:46.431779",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
